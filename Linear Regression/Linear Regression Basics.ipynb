{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds a linear regression model which will predict crop yeilds in hte region by looking at average temp, rainfall and humidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input values of temp, rainfall, humidity in a numpy array\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target  value of crop yield, apples,oranges.\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 73.,  67.,  43.],\n        [ 91.,  88.,  64.],\n        [ 87., 134.,  58.],\n        [102.,  43.,  37.],\n        [ 69.,  96.,  70.]])tensor([[ 56.,  70.],\n        [ 81., 101.],\n        [119., 133.],\n        [ 22.,  37.],\n        [103., 119.]])\n"
    }
   ],
   "source": [
    "#Converting inputs and targets to tensors\n",
    "tensor_inputs = torch.from_numpy(inputs)\n",
    "tensor_targets = torch.from_numpy(targets)\n",
    "print(tensor_inputs,tensor_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model simply performs matrix multiplication. \n",
    "\n",
    "Note `@ operator` represents matrix multiplication in pytorch. and a `.t` represents transpose of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perdications Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 50.7197, -11.8145],\n        [ 57.0893, -25.6647],\n        [ 78.5908,  36.1860],\n        [ 67.1980, -37.7570],\n        [ 39.0483, -19.6343]], grad_fn=<AddBackward0>)\n"
    }
   ],
   "source": [
    "predictions = model(tensor_inputs)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the predictions with actual target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 56.,  70.],\n        [ 81., 101.],\n        [119., 133.],\n        [ 22.,  37.],\n        [103., 119.]])\n"
    }
   ],
   "source": [
    "print(tensor_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference is calculated between `predictions` and `targets`. The `.numel()` method gives number of elements in a tensor, and `.sum()` method gives the sum of elements in a tensor. Here the mean squared error (MSE) is being calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(6528.3765, grad_fn=<DivBackward0>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = predictions - tensor_targets\n",
    "torch.sum(diff * diff)/ diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function is used to evaluate how well the model is perofrming. In this case we will use MSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(6528.3765, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "loss = mse(predictions, tensor_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 0.7635,  0.4317, -0.7828],\n        [-0.2855,  1.1196, -1.5345]], requires_grad=True)\ntensor([[-1175.8833, -2413.7222, -1381.0737],\n        [-8622.5488, -9224.9170, -5942.0371]])\n"
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is a quadratic function and the object is to find the set of weights and biases where the loss is lowest. Now the weight and baises gradients are reset to 0. This is done because the `.backward()` method accumulates the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[0., 0., 0.],\n        [0., 0., 0.]])tensor([0., 0.])\n"
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting weights and biases using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 50.7197, -11.8145],\n        [ 57.0893, -25.6647],\n        [ 78.5908,  36.1860],\n        [ 67.1980, -37.7570],\n        [ 39.0483, -19.6343]], grad_fn=<AddBackward0>)\ntensor(6528.3765, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "predictions = model(tensor_inputs)\n",
    "print(predictions)\n",
    "loss = mse(predictions, tensor_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the gradients for the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[-1175.8833, -2413.7222, -1381.0737],\n        [-8622.5488, -9224.9170, -5942.0371]])\ntensor([ -17.6708, -103.7369])\n"
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the weights and biases using the gradients. \n",
    "Here `torch.no_grad()` is beign used so that the gradients don't change during the computations of new weights and baises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 0.7753,  0.4558, -0.7690],\n        [-0.1992,  1.2119, -1.4750]], requires_grad=True)tensor([-0.2795, -0.0063], requires_grad=True)\n"
    }
   ],
   "source": [
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(4671.5146, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "predictions = model(tensor_inputs)\n",
    "loss = mse(predictions, tensor_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss has thus been minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train for multiple epochs, thats is multiple for loops and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[ 57.1181,  70.3101],\n        [ 82.2364, 100.6692],\n        [118.7008, 132.9589],\n        [ 21.0875,  37.0153],\n        [101.9128, 119.1375]], grad_fn=<AddBackward0>)\ntensor([[ 56.,  70.],\n        [ 81., 101.],\n        [119., 133.],\n        [ 22.,  37.],\n        [103., 119.]])\ntensor(0.5109, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    predictions = model(tensor_inputs)\n",
    "    loss = mse(predictions, tensor_targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "print(predictions)\n",
    "print(tensor_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}